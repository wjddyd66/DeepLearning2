{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계 기반 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "말뭉치 전처리 과정: Text를 단어로 자른 뒤 고유의 ID를 붙여주는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 확인 You say goodbye and I say hello\n",
      "단어 확인 ['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello']\n",
      "id_to_word 확인 {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello'}\n",
      "word_to_id 확인 {'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5}\n",
      "결과 확인 [0 1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello'\n",
    "print('text 확인', text)\n",
    "#소문자로 변경\n",
    "text = text.lower()\n",
    "#마침표 처리\n",
    "text = text.replace('.', ' .')\n",
    "#Text => Word\n",
    "words = text.split(' ')\n",
    "print('단어 확인',words)\n",
    "\n",
    "#말뭉치 전처리 과정 Vocab 사전 만드는 과정\n",
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word\n",
    "        \n",
    "print('id_to_word 확인',id_to_word)\n",
    "print('word_to_id 확인',word_to_id)\n",
    "\n",
    "# Text 말뭉치 전처리 결과\n",
    "import numpy as np\n",
    "corpus = [word_to_id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "print('결과 확인', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 과정을 한번에 해결하는 Method이다.  \n",
    "return 으로서 word_to_id, id_to_word, corpus를 Return하므로 위의 과정을 한번에 처리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 선언한 Method를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus:  [0 1 2 3 4 1 5]\n",
      "word_to_id:  {'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5}\n",
      "id_to_word:  {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello'}\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print('corpus: ',corpus)\n",
    "print('word_to_id: ',word_to_id)\n",
    "print('id_to_word: ',id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동시 발생 행렬 선언  \n",
    "<table class=\"table\">\n",
    "\t<tbody>\n",
    "\t<tr>\n",
    "\t\t<td></td>\n",
    "\t\t<td>you</td>\n",
    "\t\t<td>say</td>\n",
    "\t\t<td>goodbye</td>\n",
    "\t\t<td>and</td>\n",
    "\t\t<td>i</td>\n",
    "\t\t<td>hello</td>\n",
    "\t\t<td>.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>you</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>say</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>goodbye</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>and</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>i</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>hello</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>.</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>0</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0</td>\n",
    "\t</tr>\n",
    "\n",
    "</tbody>\n",
    "</table>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[1 0 1 0 1 1 0]\n",
      "[0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "C = np.array([\n",
    "    [0,1,0,0,0,0,0],\n",
    "    [1,0,1,0,1,1,0],\n",
    "    [0,1,0,1,0,0,0],\n",
    "    [0,0,1,0,1,0,0],\n",
    "    [0,1,0,1,0,0,0],\n",
    "    [0,1,0,0,0,0,1],\n",
    "    [0,0,0,0,0,1,0],\n",
    "],dtype=np.int32)\n",
    "print(C[0])\n",
    "print(C[1])\n",
    "print(C[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 Method는 위와 같은 과정을 수행하는 Method이다.\n",
    "- corpus: 말뭉치\n",
    "- vocab_size: vocab_size\n",
    "- window_size: window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "\n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "\n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**코사인 유사도 식**  \n",
    "<p>$$similarity(x,y) = \\frac{x y}{||x|| ||y||} = \\frac{x_1y_1 + ... + x_ny_n}{\\sqrt{x_1^2 + ... + x_n^2}\\sqrt{y_1^2 + ... + y_n^2}}$$</p>\n",
    "위의 식은 -1 ~ 1의 값을 가지게 되고 각 값에 대한 그림은 아래와 같다.  \n",
    "<div><img src=\"https://wikidocs.net/images/page/24603/%EC%BD%94%EC%82%AC%EC%9D%B8%EC%9C%A0%EC%82%AC%EB%8F%84.PNG\" height=\"250\" width=\"600\" /></div><br>\n",
    "즉 각각의 성분이 얼만큼 유사한지를 계산하는 과정이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x ** 2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y ** 2)) + eps)\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 Method를 활용하여 Text= \"You say goodbye and I say hello\"에서 You와 I의 유사도를 비교하는 과정이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067691154799\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]  # \"you\"의 단어 벡터\n",
    "c1 = C[word_to_id['i']]    # \"i\"의 단어 벡터\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 선언한 Method를 개선하여 검색어와 가장 비슷한 단어를 추출하는 Method를 만들어보자. \n",
    "- query: 검색어\n",
    "- word_to_id: 단어에서 단어 ID로의 딕셔너리\n",
    "- id_to_word: 단어 ID에서 단어로의 딕셔너리\n",
    "- word_matrix: 단어 벡터들을 한데 모은 행렬, 각 행에는 대응하는 단어의 벡터가 저장되어있다고 가정\n",
    "- top: 상위 몇 개까지 추출할지에 관한 Parameter\n",
    "- argsort(): 배열에 담긴 원소의 인덱스를 내림차순으로 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    if query not in word_to_id:\n",
    "        print('%s(을)를 찾을 수 없습니다.' % query)\n",
    "        return\n",
    "\n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    vocab_size = len(id_to_word)\n",
    "\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "\n",
    "    # 코사인 유사도를 기준으로 내림차순으로 출력\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return\n",
    "most_similar('you',word_to_id,id_to_word,C,top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 단어 사이의 거리만으로서 판단하는 것은 매우 큰 문제점이 발생하게 된다.  \n",
    "영어에서의 **the**와같이 많이 나오는 수식어는 자주 출몰하게되어서 모든 단어와의 거리가 가까워 지게 되고 이로 인하여 많은 단어와의 상관성이 높에 나올 수 있다.  \n",
    "이러한 문제점을 해결한 방안이 **PMI**이다.  \n",
    "**PMI 식**  \n",
    "<p>$$log_2 \\frac{P(x,y)}{P(x)P(y)} = log_2 \\frac{\\frac{C(x,y)}{N}}{\\frac{C(x)}{N}\\frac{C(y)}{N}} = log_2 \\frac{C(x,y)N}{C(x)C(y)}$$</p>\n",
    "\n",
    "위의 식에서의 문제는 P(x,y) = 0 인경우 <span>$$log_20 =-\\inf$$ </span>이므로 문제가 발생하게 된다. 위와 같은 문제를 해결한 것이 **PPMI**이고 아래 식과 같다.  \n",
    "**PPMI 식**\n",
    "<p>$$PPMI(x,y) = max(0,PMI(x,y))$$</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시 발생 행렬\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "def ppmi(C, eps = 1e-8):\n",
    "    #동시 발생 행렬과 같은 크기의 행렬\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    #말뭉치에 포함된 단어 수\n",
    "    N = np.sum(C)\n",
    "    #각 단어의 발생 횟수\n",
    "    S = np.sum(C, axis=0)\n",
    "    \n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            #PMI 식\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            #PPMI 식\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "    return M\n",
    "W = ppmi(C)\n",
    "\n",
    "#유효 자릿수를 3자리로 표시\n",
    "np.set_printoptions(precision=3)\n",
    "print('동시 발생 행렬')\n",
    "print(C)\n",
    "print('-'*50)\n",
    "print('PPMI')\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 차원 감소\n",
    "위와 같은 문제를 위하여 차원감소 방법중에 SVD를 사용한다.  \n",
    "SVD에 자세한 내용은 아래 링크 참조  \n",
    "<a href=\"https://wjddyd66.github.io/ai/2019/07/24/PCA.html\">SVD 자세한 내용</a><br>\n",
    "위와 같은 식은 **numpy의 ilnalg Module**을 사용하여 구현한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시 발생 행렬\n",
      "[0 1 0 0 0 0 0]\n",
      "----------\n",
      "PPMI\n",
      "[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      "----------\n",
      "SVD\n",
      "[ 0.000e+00  3.409e-01 -3.886e-16 -1.205e-01  9.323e-01 -1.110e-16\n",
      " -1.467e-16]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SVD\n",
    "U, S, V = np.linalg.svd(W)\n",
    "\n",
    "print('동시 발생 행렬')\n",
    "print(C[0])\n",
    "print('-'*10)\n",
    "print('PPMI')\n",
    "print(W[0])\n",
    "print('-'*10)\n",
    "print('SVD')\n",
    "print(U[0])\n",
    "\n",
    "# 플롯\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PTB 데이터 셋을 활용, sklearn의 SVD를 활용하여 선언한 Method의 결과를 확인하여 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 수 계산 ...\n",
      "PPMI 계산 ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-582bc1a25760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_co_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PPMI 계산 ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppmi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'calculating SVD ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-db6f7a6e9a77>\u001b[0m in \u001b[0;36mppmi\u001b[0;34m(C, eps)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m#PMI 식\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mpmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m#PPMI 식\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataset import ptb\n",
    "\n",
    "\n",
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('동시발생 수 계산 ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('PPMI 계산 ...')\n",
    "W = ppmi(C)\n",
    "\n",
    "print('calculating SVD ...')\n",
    "try:\n",
    "    # truncated SVD (빠르다!)\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5,\n",
    "                             random_state=None)\n",
    "except ImportError:\n",
    "    # SVD (느리다)\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
