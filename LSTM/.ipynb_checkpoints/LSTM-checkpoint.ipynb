{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploding Gradients\n",
    "Exploding Gradients의 해결방법으로 **Gradients Clipping**이 존재한다.  \n",
    "Gradients Clipping에대한 식은 아래와 같다.  \n",
    "<p>$$if ||\\hat{g}|| \\ge threshold$$</p>\n",
    "<p>$$\\hat{g} =  \\frac{threshold}{||\\hat{g}||}\\hat{g}$$</p>\n",
    "\n",
    "**Parameter 설명**  \n",
    "$$\\hat{g}$$\n",
    "사용하는 모든 매개변수의 기울기를 하나로 모은 것\n",
    "$$||\\hat{g}||$$\n",
    "<span>$$\\hat{g}$$ </span>에 L2 norm 적용\n",
    "$$threshold$$\n",
    "문턱값\n",
    "\n",
    "위와같이 문턱값을 초과하면 문턱값으로 값을 대입하는 것으로 **Exploding Gradients**를 해결할 수 있는 것을 알 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: [5.44799518 3.47358019 5.65014947 5.43636298 3.88975196 9.74236234\n",
      " 2.28613427 5.28779157 4.54053003]\n",
      "after: [1.02768352 0.6552394  1.06581693 1.02548928 0.73374404 1.83775222\n",
      " 0.43124534 0.99746349 0.85650367]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate\n",
    "\n",
    "\n",
    "print('before:', dW1.flatten())\n",
    "clip_grads(grads, max_norm)\n",
    "print('after:', dW1.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- σ(시그모이드): 0 ~ 1의 범위를 가지게 출력형태를 바꿔주며 데이터를 얼마만큼 통과시킬지를 정하는 비율\n",
    "- tanh(하이퍼 볼릭 탄젠트): -1 ~ 1의 범위를 가지게 출력형태를 바꿔주며 실질적인 정보의 비율\n",
    "- Output gate: <span>$$o = \\sigma (W_{xh_o}x_t +W_{hh_o}h_{t-1} + b_{h_o})$$</span>: 다음 시간의 Hidden Layer에서 얼만큼 중요한가를 나타내는 상수\n",
    "- Forget gate: <span>$$f_t = \\sigma (W_{xh_f}x_t +W_{hh_f}h_{t-1} + b_{h_f})$$</span>: 과거 정보를 잊기 위한 게이트(0 ~ 1사이의 값을 가지는 Scalar로서 얼만큼 잊을지 비율로서 표현)\n",
    "-  <span>$$g$$</span>: <span>$$tanh(W_{xh_g}x_t +W_{hh_g}h_{t-1} + b_{h_g})$$</span>: tanh를 사용하여 현재 LSTM Layer에서의 실질적인 정보의 비율\n",
    "- Input gate: <span>$$i_t = \\sigma (W_{xh_i}x_t +W_{hh_i}h_{t-1} + b_{h_i})$$</span>: 현재 정보를 기억하기 위한 게이트(0 ~ 1사이의 값을 가지는 Scalar로서 얼만큼 기억할 비율로서 표현)\n",
    "- <span>$$c_t$$</span>: 기억 셀로서 과거로부터 시각 t까지에 필요한 모든 정보가 저장된 Cell, <span>$$c_t = f \\odot c_{t-1} + g \\odot i $$</span>\n",
    "- <span>$$h_t$$</span>: <span>$$o \\odot tanh(c_t)$$</span>: Hidden Layer의 출력 o가 Sigmoid의 Output으로서 상수이므로 <span>$$\\odot$$ </span>사용\n",
    "\n",
    "위와 같은 LSTM의 망을 **Affine 변환**을 통해 빠르게 계산수행을 위해 아래와 같이 망을 최종적으로 구성한다.  \n",
    "<div><img src=\"http://i.imgur.com/73zzDsC.png\" height=\"100%\" width=\"100%\" /></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Wx: 입력 x에 대한 가중치 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        Wh: 은닉 상태 h에 대한 가장추 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        b: 편향（4개분의 편향이 담겨 있음）\n",
    "        '''\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "\n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "\n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "\n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "\n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "\n",
    "        dc_prev = ds * f\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time LSTM\n",
    "T개분의 시계열 데이터를 한꺼번에 처리하는 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 정의한 **Time LSTM**을 활용하여 Softmax직전까지의 Rnnlm을 구성하는 코드이다.  \n",
    "즉, Embedding -> Time LSTM -> Time Affine까지의 계층 구현이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 구현한 Rnnlm을 Train하는 Code이다.  \n",
    "이전 Post에서의 Simple Rnnlm과 다른점은 **Exploding Gradients을 해결하기 위하여 Exploding Clipping을 사용한 것 이다.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 10002.11\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 2612.64\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 7[s] | 퍼플렉서티 1253.93\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 11[s] | 퍼플렉서티 977.90\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 15[s] | 퍼플렉서티 782.97\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 19[s] | 퍼플렉서티 640.05\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 23[s] | 퍼플렉서티 657.03\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 27[s] | 퍼플렉서티 595.01\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 31[s] | 퍼플렉서티 587.60\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 35[s] | 퍼플렉서티 589.98\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 39[s] | 퍼플렉서티 504.04\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 43[s] | 퍼플렉서티 487.82\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 47[s] | 퍼플렉서티 441.64\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 51[s] | 퍼플렉서티 453.01\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 55[s] | 퍼플렉서티 448.88\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 59[s] | 퍼플렉서티 385.96\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 62[s] | 퍼플렉서티 341.99\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 66[s] | 퍼플렉서티 401.90\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 70[s] | 퍼플렉서티 400.60\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 74[s] | 퍼플렉서티 337.25\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 78[s] | 퍼플렉서티 348.49\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 82[s] | 퍼플렉서티 337.72\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 86[s] | 퍼플렉서티 322.69\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 90[s] | 퍼플렉서티 322.98\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 94[s] | 퍼플렉서티 297.17\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 98[s] | 퍼플렉서티 310.30\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 102[s] | 퍼플렉서티 300.94\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 106[s] | 퍼플렉서티 316.70\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 110[s] | 퍼플렉서티 282.51\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 114[s] | 퍼플렉서티 256.36\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 117[s] | 퍼플렉서티 332.35\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 121[s] | 퍼플렉서티 312.07\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 125[s] | 퍼플렉서티 279.08\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 129[s] | 퍼플렉서티 265.73\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 133[s] | 퍼플렉서티 225.37\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 137[s] | 퍼플렉서티 248.23\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 141[s] | 퍼플렉서티 257.95\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 145[s] | 퍼플렉서티 216.85\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 148[s] | 퍼플렉서티 232.17\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 152[s] | 퍼플렉서티 212.84\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 156[s] | 퍼플렉서티 240.15\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 160[s] | 퍼플렉서티 221.89\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 164[s] | 퍼플렉서티 224.21\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 168[s] | 퍼플렉서티 218.75\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 171[s] | 퍼플렉서티 201.84\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 175[s] | 퍼플렉서티 252.01\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 179[s] | 퍼플렉서티 224.91\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 183[s] | 퍼플렉서티 226.88\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 187[s] | 퍼플렉서티 241.68\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 191[s] | 퍼플렉서티 227.96\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 195[s] | 퍼플렉서티 191.41\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 198[s] | 퍼플렉서티 224.38\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 202[s] | 퍼플렉서티 205.30\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 206[s] | 퍼플렉서티 193.62\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 210[s] | 퍼플렉서티 166.77\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 214[s] | 퍼플렉서티 187.85\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 217[s] | 퍼플렉서티 226.06\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 221[s] | 퍼플렉서티 206.72\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 225[s] | 퍼플렉서티 195.24\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 229[s] | 퍼플렉서티 188.03\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 233[s] | 퍼플렉서티 161.95\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 237[s] | 퍼플렉서티 157.26\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 241[s] | 퍼플렉서티 184.21\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 245[s] | 퍼플렉서티 169.27\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 248[s] | 퍼플렉서티 176.27\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 252[s] | 퍼플렉서티 218.85\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 257[s] | 퍼플렉서티 208.74\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 258[s] | 퍼플렉서티 222.52\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 262[s] | 퍼플렉서티 201.90\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 266[s] | 퍼플렉서티 188.17\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 270[s] | 퍼플렉서티 172.98\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 274[s] | 퍼플렉서티 156.18\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 278[s] | 퍼플렉서티 149.92\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 282[s] | 퍼플렉서티 157.67\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 285[s] | 퍼플렉서티 176.64\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 289[s] | 퍼플렉서티 188.88\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 293[s] | 퍼플렉서티 198.10\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 297[s] | 퍼플렉서티 183.06\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 301[s] | 퍼플렉서티 181.69\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 305[s] | 퍼플렉서티 174.23\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 309[s] | 퍼플렉서티 184.09\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 313[s] | 퍼플렉서티 184.19\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 317[s] | 퍼플렉서티 163.63\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 321[s] | 퍼플렉서티 136.47\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 325[s] | 퍼플렉서티 171.07\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 329[s] | 퍼플렉서티 195.36\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 333[s] | 퍼플렉서티 151.19\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 337[s] | 퍼플렉서티 165.64\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 341[s] | 퍼플렉서티 152.26\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 345[s] | 퍼플렉서티 160.74\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 349[s] | 퍼플렉서티 155.27\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 353[s] | 퍼플렉서티 154.11\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 357[s] | 퍼플렉서티 168.13\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 360[s] | 퍼플렉서티 172.89\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 364[s] | 퍼플렉서티 174.48\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 368[s] | 퍼플렉서티 151.60\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 372[s] | 퍼플렉서티 138.50\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 376[s] | 퍼플렉서티 188.00\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 379[s] | 퍼플렉서티 180.62\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 383[s] | 퍼플렉서티 163.49\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 387[s] | 퍼플렉서티 152.87\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 391[s] | 퍼플렉서티 126.80\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 395[s] | 퍼플렉서티 149.43\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 398[s] | 퍼플렉서티 158.55\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 402[s] | 퍼플렉서티 131.80\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 406[s] | 퍼플렉서티 128.58\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 410[s] | 퍼플렉서티 135.00\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 414[s] | 퍼플렉서티 145.73\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 417[s] | 퍼플렉서티 142.97\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 421[s] | 퍼플렉서티 142.50\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 425[s] | 퍼플렉서티 145.37\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 429[s] | 퍼플렉서티 128.75\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 432[s] | 퍼플렉서티 165.92\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 436[s] | 퍼플렉서티 146.13\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 440[s] | 퍼플렉서티 153.14\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 444[s] | 퍼플렉서티 163.35\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 448[s] | 퍼플렉서티 154.18\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 452[s] | 퍼플렉서티 131.02\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 456[s] | 퍼플렉서티 156.54\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 460[s] | 퍼플렉서티 141.10\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 463[s] | 퍼플렉서티 127.02\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 467[s] | 퍼플렉서티 110.87\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 471[s] | 퍼플렉서티 118.79\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 475[s] | 퍼플렉서티 150.53\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 479[s] | 퍼플렉서티 141.00\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 483[s] | 퍼플렉서티 131.55\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 487[s] | 퍼플렉서티 132.01\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 491[s] | 퍼플렉서티 111.17\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 495[s] | 퍼플렉서티 108.55\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 499[s] | 퍼플렉서티 129.98\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 503[s] | 퍼플렉서티 122.20\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 506[s] | 퍼플렉서티 122.16\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 510[s] | 퍼플렉서티 157.19\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 514[s] | 퍼플렉서티 153.15\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 515[s] | 퍼플렉서티 160.96\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 519[s] | 퍼플렉서티 144.13\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 523[s] | 퍼플렉서티 135.85\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 527[s] | 퍼플렉서티 126.47\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 530[s] | 퍼플렉서티 115.98\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 534[s] | 퍼플렉서티 104.72\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 538[s] | 퍼플렉서티 115.11\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 542[s] | 퍼플렉서티 126.02\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 546[s] | 퍼플렉서티 141.58\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 550[s] | 퍼플렉서티 151.07\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 553[s] | 퍼플렉서티 140.30\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 557[s] | 퍼플렉서티 138.86\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 561[s] | 퍼플렉서티 133.45\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 565[s] | 퍼플렉서티 138.82\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 568[s] | 퍼플렉서티 140.75\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 572[s] | 퍼플렉서티 123.58\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 576[s] | 퍼플렉서티 101.47\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 580[s] | 퍼플렉서티 125.12\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 584[s] | 퍼플렉서티 151.16\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 587[s] | 퍼플렉서티 113.31\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 591[s] | 퍼플렉서티 127.89\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 595[s] | 퍼플렉서티 113.06\n",
      "| 에폭 3 |  반복 441 / 1327 | 시간 599[s] | 퍼플렉서티 122.34\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 603[s] | 퍼플렉서티 116.07\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 607[s] | 퍼플렉서티 118.93\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 610[s] | 퍼플렉서티 128.21\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 614[s] | 퍼플렉서티 137.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 3 |  반복 541 / 1327 | 시간 618[s] | 퍼플렉서티 135.76\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 622[s] | 퍼플렉서티 117.65\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 626[s] | 퍼플렉서티 105.81\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 629[s] | 퍼플렉서티 149.75\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 633[s] | 퍼플렉서티 142.67\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 637[s] | 퍼플렉서티 129.89\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 641[s] | 퍼플렉서티 118.54\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 645[s] | 퍼플렉서티 98.89\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 648[s] | 퍼플렉서티 117.98\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 652[s] | 퍼플렉서티 125.60\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 656[s] | 퍼플렉서티 106.45\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 660[s] | 퍼플렉서티 101.67\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 664[s] | 퍼플렉서티 103.33\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 667[s] | 퍼플렉서티 116.13\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 671[s] | 퍼플렉서티 116.93\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 675[s] | 퍼플렉서티 114.14\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 679[s] | 퍼플렉서티 120.66\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 683[s] | 퍼플렉서티 106.21\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 686[s] | 퍼플렉서티 132.95\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 690[s] | 퍼플렉서티 118.82\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 694[s] | 퍼플렉서티 126.14\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 698[s] | 퍼플렉서티 131.81\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 702[s] | 퍼플렉서티 124.50\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 705[s] | 퍼플렉서티 108.88\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 709[s] | 퍼플렉서티 129.18\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 713[s] | 퍼플렉서티 118.20\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 717[s] | 퍼플렉서티 102.81\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 721[s] | 퍼플렉서티 89.43\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 724[s] | 퍼플렉서티 95.23\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 728[s] | 퍼플렉서티 120.78\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 732[s] | 퍼플렉서티 114.62\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 736[s] | 퍼플렉서티 105.67\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 740[s] | 퍼플렉서티 109.79\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 743[s] | 퍼플렉서티 93.74\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 747[s] | 퍼플렉서티 88.12\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 751[s] | 퍼플렉서티 106.11\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 755[s] | 퍼플렉서티 104.03\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 758[s] | 퍼플렉서티 100.80\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 762[s] | 퍼플렉서티 129.26\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 766[s] | 퍼플렉서티 127.55\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 767[s] | 퍼플렉서티 133.37\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 771[s] | 퍼플렉서티 121.58\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 775[s] | 퍼플렉서티 107.51\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 779[s] | 퍼플렉서티 108.22\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 783[s] | 퍼플렉서티 95.27\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 787[s] | 퍼플렉서티 85.92\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 791[s] | 퍼플렉서티 95.33\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 794[s] | 퍼플렉서티 103.89\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 798[s] | 퍼플렉서티 116.51\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 802[s] | 퍼플렉서티 129.47\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 806[s] | 퍼플렉서티 120.25\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 810[s] | 퍼플렉서티 121.27\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 814[s] | 퍼플렉서티 115.09\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 818[s] | 퍼플렉서티 114.95\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 822[s] | 퍼플렉서티 120.56\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 826[s] | 퍼플렉서티 104.30\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 830[s] | 퍼플렉서티 83.48\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 833[s] | 퍼플렉서티 100.67\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 837[s] | 퍼플렉서티 127.79\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 841[s] | 퍼플렉서티 95.63\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 845[s] | 퍼플렉서티 108.21\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 849[s] | 퍼플렉서티 93.33\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 853[s] | 퍼플렉서티 102.78\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 857[s] | 퍼플렉서티 98.19\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 861[s] | 퍼플렉서티 102.86\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 864[s] | 퍼플렉서티 107.67\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 868[s] | 퍼플렉서티 116.90\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 872[s] | 퍼플렉서티 112.60\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 876[s] | 퍼플렉서티 102.04\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 880[s] | 퍼플렉서티 89.59\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 884[s] | 퍼플렉서티 127.46\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 888[s] | 퍼플렉서티 121.93\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 891[s] | 퍼플렉서티 111.10\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 895[s] | 퍼플렉서티 101.67\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 899[s] | 퍼플렉서티 84.77\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 903[s] | 퍼플렉서티 102.30\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 907[s] | 퍼플렉서티 106.75\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 911[s] | 퍼플렉서티 94.69\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 915[s] | 퍼플렉서티 87.02\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 918[s] | 퍼플렉서티 87.80\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 922[s] | 퍼플렉서티 98.88\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 926[s] | 퍼플렉서티 103.16\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 930[s] | 퍼플렉서티 98.23\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 933[s] | 퍼플렉서티 104.74\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 937[s] | 퍼플렉서티 91.36\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 941[s] | 퍼플렉서티 116.61\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 945[s] | 퍼플렉서티 103.64\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 949[s] | 퍼플렉서티 112.09\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 952[s] | 퍼플렉서티 112.60\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 956[s] | 퍼플렉서티 106.87\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 960[s] | 퍼플렉서티 97.35\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 964[s] | 퍼플렉서티 113.81\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 968[s] | 퍼플렉서티 103.06\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 971[s] | 퍼플렉서티 89.07\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 975[s] | 퍼플렉서티 79.22\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 979[s] | 퍼플렉서티 80.43\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 983[s] | 퍼플렉서티 102.97\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 987[s] | 퍼플렉서티 99.40\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 990[s] | 퍼플렉서티 91.46\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 994[s] | 퍼플렉서티 94.33\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 998[s] | 퍼플렉서티 83.09\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 1002[s] | 퍼플렉서티 75.51\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 1006[s] | 퍼플렉서티 91.76\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 1009[s] | 퍼플렉서티 92.87\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 1013[s] | 퍼플렉서티 89.60\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 1017[s] | 퍼플렉서티 111.22\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 1021[s] | 퍼플렉서티 109.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  134.85544110439733\n"
     ]
    }
   ],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 35     # RNN을 펼치는 크기\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# 모델 생성\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 기울기 클리핑을 적용하여 학습\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n",
    "            eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "\n",
    "# 매개변수 저장\n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 Time LSTM에서 여러가지 기법을 사용하여 좀 더 Model의 퍼블렉서티의 값이 낮아지게 하는 것을 목표로 한다.  \n",
    "\n",
    "**1. Layer Depth 증가**  \n",
    "Layer Depth가 증가하게 되면 비선형성이 더욱 증가되어 Data를 예측하는 성능이 높아지게 된다.  \n",
    "하지만 이러한 Layer Depth를 증가시키면 크게 2가지의 문제가 발생하게 된다.  \n",
    "1. Layer Depth가 깊어질수록 Hyper Parameter의 수가 증가하게 되며, 학습에 사용할 데이터 양이 제한적일 경우 Overfitting에 빠질 위험이 있다.\n",
    "2. Layer Depth가 증가하게 되면 연산량이 늘어나게 된다.\n",
    "\n",
    "현재 사용하는 PTB데이터셋의 언어 모델에서는 LSTM의 층 수는 2~4정도일때 좋은 결과를 만든다고 하여 2층으로 선정하였다.  \n",
    "\n",
    "**2. Dropout**  \n",
    "DropOut Dropout은 Overfitting을 막기위한 방법으로 뉴럴 네트워크가 학습중일때, 랜덤하게 뉴런을 꺼서 학습함으로써, 학습이 학습용 데이터로 치우치는 현상을 막아준다.  \n",
    "<a href=\"https://wjddyd66.github.io/dl/2019/08/31/NeuralNetwork-(5)-Others.html\">Dropout의 자세한 내용</a><br>\n",
    "\n",
    "**LSTM 의 경우 Dropout의 위치가 중요하게 된다. Dropout의 위치에 따라서 timestep의 정보가 지워져서 시계열 데이터를 사용하는데 어려움을 겪을 수 있기 때문이다.**  \n",
    "\n",
    "따라서 LSTM에서 권장하는 Dropout의 위치는 다음과 같다.  \n",
    "<div><img src=\"https://nmhkahn.github.io/assets/RNN-Reg/p1-dropout.png\" height=\"250\" width=\"600\" /></div>\n",
    "\n",
    "위 그림에서 점선은 dropout이 적용된 연결이고 실선은 dropout이 적용이 되지 않은 것이다. 제시한 방법을 곱씹어보면 이전 timestep에서 온 정보는 dropout 하지 말고, **현재 timestep에서 들어온 입력값 혹은 이전 레이어의 값만 dropout** 하는 의미이다.  \n",
    "현재 timestep에서 이전 레이어인 <span>$$h_t^{l-1}$$</span>에 dropout을 적용했는데 과거 timestep의 정보를 지우지 않게 하기 위해 recurrent한 연결 (과거 timestep)에 dropout을 적용하지 않은 것으로 보인다. 다시 정리하면, 일반적인 dropout을 적용한다면 먼 과거의 정보를 잃어버려 학습하는데 어려움을 갖지만, **non-recurrent한 연결만 dropout을 적용하면 과거 중요 정보를 희생하지 않아도 regularization을 사용**할 수 있다.\n",
    "\n",
    "위의 내용을 정리하면 즉, LSTM의 결과 <span>$$c_t^{l}, h_t^{l}$$</span>에서 이전 timestep의 내용을 가지고 있는 <span>$$c_t^{l}$$</span>에 dropout을 적용하게 되면 timestep의 정보가 지워질 수 있다는 것 이다.  \n",
    "\n",
    "**3. 가중치 공유(Weight Tying)**  \n",
    "**Weight Tying** 란 입력-임베딩 레이어와 출력 과 softmax 레이어 사이의 가중치 매트릭스 공유 즉, 두 개의 가중치 행렬을 사용하는 대신 하나의 가중치 행렬 만 사용하는 방법이다.  \n",
    "즉 Embedding을 Encoding이라고 생각하게 되면, Encoding과 Decoding의 방식을 같게한다고 생각할 수 있다.  \n",
    "실제로 가중치 공유를 하게되면 다음과 같은 2가지 장점을 생각할 수 있다.\n",
    "1. Hyper Parameter의 수가 감소하게 되여 Overfitting에 빠질 위험 감소\n",
    "2. Update해야할 Weight감소로 인하여 학습 속도 개선\n",
    "\n",
    "\n",
    "\n",
    "**실제 구현**  \n",
    "- LSTM 계층의 다층화(2층)\n",
    "- Dropout 사용\n",
    "- 가중치 공유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "from common.np import *  # import numpy as np\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650,\n",
    "                 hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)  # weight tying!!\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**결과 확인**  \n",
    "이전 Train과 달리 검증 데이터로 퍼플렉서티를 평가하고, 그 값이 나빠졌을 경우에만 학습률을 낮추는 방법으로 Train을 하였다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 1[s] | 퍼플렉서티 10000.24\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 25[s] | 퍼플렉서티 3268.14\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 50[s] | 퍼플렉서티 1861.89\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 75[s] | 퍼플렉서티 1299.86\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 100[s] | 퍼플렉서티 1099.30\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 125[s] | 퍼플렉서티 833.11\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 149[s] | 퍼플렉서티 789.12\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 174[s] | 퍼플렉서티 695.42\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 202[s] | 퍼플렉서티 683.55\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 228[s] | 퍼플렉서티 673.48\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 253[s] | 퍼플렉서티 586.21\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 279[s] | 퍼플렉서티 577.16\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 304[s] | 퍼플렉서티 511.99\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 329[s] | 퍼플렉서티 536.13\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 354[s] | 퍼플렉서티 523.40\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 379[s] | 퍼플렉서티 452.04\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 404[s] | 퍼플렉서티 389.26\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 430[s] | 퍼플렉서티 443.76\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 454[s] | 퍼플렉서티 467.76\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 479[s] | 퍼플렉서티 382.34\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 504[s] | 퍼플렉서티 399.99\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 529[s] | 퍼플렉서티 392.48\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 554[s] | 퍼플렉서티 374.61\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 579[s] | 퍼플렉서티 370.61\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 604[s] | 퍼플렉서티 339.15\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 629[s] | 퍼플렉서티 358.24\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 654[s] | 퍼플렉서티 340.19\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 679[s] | 퍼플렉서티 359.60\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 705[s] | 퍼플렉서티 325.89\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 730[s] | 퍼플렉서티 288.28\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 755[s] | 퍼플렉서티 381.05\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 780[s] | 퍼플렉서티 342.74\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 805[s] | 퍼플렉서티 315.39\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 830[s] | 퍼플렉서티 299.80\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 855[s] | 퍼플렉서티 257.15\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 880[s] | 퍼플렉서티 276.92\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 906[s] | 퍼플렉서티 286.93\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 931[s] | 퍼플렉서티 247.60\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 956[s] | 퍼플렉서티 261.24\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 981[s] | 퍼플렉서티 243.91\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 1007[s] | 퍼플렉서티 269.75\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 1031[s] | 퍼플렉서티 251.92\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 1056[s] | 퍼플렉서티 254.73\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 1081[s] | 퍼플렉서티 250.93\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 1106[s] | 퍼플렉서티 230.84\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 1131[s] | 퍼플렉서티 282.08\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 1156[s] | 퍼플렉서티 259.31\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 1180[s] | 퍼플렉서티 256.70\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 1205[s] | 퍼플렉서티 276.36\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 1230[s] | 퍼플렉서티 256.35\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 1255[s] | 퍼플렉서티 215.04\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 1280[s] | 퍼플렉서티 251.77\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 1305[s] | 퍼플렉서티 232.88\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 1330[s] | 퍼플렉서티 219.14\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 1355[s] | 퍼플렉서티 189.35\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 1380[s] | 퍼플렉서티 216.69\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 1406[s] | 퍼플렉서티 254.03\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 1432[s] | 퍼플렉서티 231.26\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 1457[s] | 퍼플렉서티 220.55\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 1482[s] | 퍼플렉서티 210.19\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 1507[s] | 퍼플렉서티 178.92\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 1532[s] | 퍼플렉서티 179.82\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 1558[s] | 퍼플렉서티 208.25\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 1583[s] | 퍼플렉서티 193.18\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 1608[s] | 퍼플렉서티 198.08\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 1633[s] | 퍼플렉서티 248.73\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 1658[s] | 퍼플렉서티 232.99\n",
      "퍼플렉서티 평가 중 ...\n",
      "209 / 210\n",
      "검증 퍼플렉서티:  198.15944247339417\n",
      "--------------------------------------------------\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 1[s] | 퍼플렉서티 291.25\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 26[s] | 퍼플렉서티 230.18\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 51[s] | 퍼플렉서티 212.38\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 76[s] | 퍼플렉서티 196.14\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 102[s] | 퍼플렉서티 180.26\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 127[s] | 퍼플렉서티 169.25\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 152[s] | 퍼플렉서티 183.08\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 177[s] | 퍼플렉서티 200.20\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 202[s] | 퍼플렉서티 216.40\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 227[s] | 퍼플렉서티 223.49\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 252[s] | 퍼플렉서티 207.51\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 277[s] | 퍼플렉서티 205.18\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 303[s] | 퍼플렉서티 196.51\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 328[s] | 퍼플렉서티 214.97\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 355[s] | 퍼플렉서티 203.92\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 380[s] | 퍼플렉서티 186.65\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 405[s] | 퍼플렉서티 155.34\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 430[s] | 퍼플렉서티 199.72\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 455[s] | 퍼플렉서티 215.51\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 479[s] | 퍼플렉서티 173.43\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 504[s] | 퍼플렉서티 194.71\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 529[s] | 퍼플렉서티 173.83\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 554[s] | 퍼플렉서티 179.14\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 580[s] | 퍼플렉서티 183.31\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 605[s] | 퍼플렉서티 176.77\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 630[s] | 퍼플렉서티 191.26\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 654[s] | 퍼플렉서티 191.78\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 680[s] | 퍼플렉서티 200.89\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 705[s] | 퍼플렉서티 171.77\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 729[s] | 퍼플렉서티 158.07\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 755[s] | 퍼플렉서티 214.89\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 780[s] | 퍼플렉서티 203.30\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 805[s] | 퍼플렉서티 185.92\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 830[s] | 퍼플렉서티 171.55\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 856[s] | 퍼플렉서티 145.78\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 881[s] | 퍼플렉서티 169.11\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 907[s] | 퍼플렉서티 176.37\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 932[s] | 퍼플렉서티 150.53\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 957[s] | 퍼플렉서티 149.82\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 983[s] | 퍼플렉서티 148.77\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 1009[s] | 퍼플렉서티 169.81\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 1034[s] | 퍼플렉서티 163.46\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 1059[s] | 퍼플렉서티 162.90\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 1084[s] | 퍼플렉서티 160.23\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 1111[s] | 퍼플렉서티 147.71\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 1133[s] | 퍼플렉서티 190.13\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 1155[s] | 퍼플렉서티 166.38\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 1176[s] | 퍼플렉서티 169.69\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 1198[s] | 퍼플렉서티 183.56\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 1220[s] | 퍼플렉서티 174.32\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 1243[s] | 퍼플렉서티 148.24\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 1265[s] | 퍼플렉서티 176.67\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 1288[s] | 퍼플렉서티 158.88\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 1309[s] | 퍼플렉서티 148.02\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 1331[s] | 퍼플렉서티 123.96\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 1353[s] | 퍼플렉서티 137.09\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 1374[s] | 퍼플렉서티 171.51\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 1396[s] | 퍼플렉서티 161.50\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 1418[s] | 퍼플렉서티 147.90\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 1440[s] | 퍼플렉서티 148.12\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 1461[s] | 퍼플렉서티 125.89\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 1483[s] | 퍼플렉서티 124.39\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 1505[s] | 퍼플렉서티 147.86\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 1527[s] | 퍼플렉서티 138.04\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 1549[s] | 퍼플렉서티 140.43\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 1571[s] | 퍼플렉서티 178.66\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 1593[s] | 퍼플렉서티 171.01\n",
      "퍼플렉서티 평가 중 ...\n",
      "209 / 210\n",
      "검증 퍼플렉서티:  145.69148880984812\n",
      "--------------------------------------------------\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 1[s] | 퍼플렉서티 218.46\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 22[s] | 퍼플렉서티 161.48\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 44[s] | 퍼플렉서티 152.46\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 66[s] | 퍼플렉서티 143.14\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 88[s] | 퍼플렉서티 129.10\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 110[s] | 퍼플렉서티 121.11\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 132[s] | 퍼플렉서티 134.52\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 154[s] | 퍼플렉서티 146.92\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 176[s] | 퍼플렉서티 162.48\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 198[s] | 퍼플렉서티 167.63\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 219[s] | 퍼플렉서티 160.02\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 241[s] | 퍼플렉서티 156.03\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 263[s] | 퍼플렉서티 151.71\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 285[s] | 퍼플렉서티 163.17\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 307[s] | 퍼플렉서티 158.27\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 331[s] | 퍼플렉서티 140.11\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 353[s] | 퍼플렉서티 112.00\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 375[s] | 퍼플렉서티 151.51\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 397[s] | 퍼플렉서티 164.86\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 419[s] | 퍼플렉서티 132.80\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 441[s] | 퍼플렉서티 149.10\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 463[s] | 퍼플렉서티 130.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 3 |  반복 441 / 1327 | 시간 485[s] | 퍼플렉서티 139.50\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 507[s] | 퍼플렉서티 138.08\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 529[s] | 퍼플렉서티 135.04\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 551[s] | 퍼플렉서티 149.60\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 573[s] | 퍼플렉서티 153.00\n",
      "| 에폭 3 |  반복 541 / 1327 | 시간 595[s] | 퍼플렉서티 158.19\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 617[s] | 퍼플렉서티 133.15\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 639[s] | 퍼플렉서티 121.91\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 661[s] | 퍼플렉서티 170.14\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 683[s] | 퍼플렉서티 159.96\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 705[s] | 퍼플렉서티 145.27\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 727[s] | 퍼플렉서티 136.45\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 749[s] | 퍼플렉서티 116.32\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 771[s] | 퍼플렉서티 137.36\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 793[s] | 퍼플렉서티 140.68\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 815[s] | 퍼플렉서티 119.37\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 837[s] | 퍼플렉서티 115.40\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 859[s] | 퍼플렉서티 119.24\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 881[s] | 퍼플렉서티 139.16\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 902[s] | 퍼플렉서티 132.44\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 924[s] | 퍼플렉서티 134.07\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 946[s] | 퍼플렉서티 130.83\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 968[s] | 퍼플렉서티 119.52\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 990[s] | 퍼플렉서티 152.16\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 1012[s] | 퍼플렉서티 135.46\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 1034[s] | 퍼플렉서티 139.65\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 1056[s] | 퍼플렉서티 151.60\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 1077[s] | 퍼플렉서티 142.64\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 1099[s] | 퍼플렉서티 122.82\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 1121[s] | 퍼플렉서티 146.63\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 1143[s] | 퍼플렉서티 129.48\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 1165[s] | 퍼플렉서티 121.05\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 1187[s] | 퍼플렉서티 100.48\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 1209[s] | 퍼플렉서티 106.95\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 1230[s] | 퍼플렉서티 139.90\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 1252[s] | 퍼플렉서티 134.08\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 1274[s] | 퍼플렉서티 117.24\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 1296[s] | 퍼플렉서티 122.86\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 1318[s] | 퍼플렉서티 103.40\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 1340[s] | 퍼플렉서티 103.80\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 1361[s] | 퍼플렉서티 122.46\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 1383[s] | 퍼플렉서티 115.21\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 1405[s] | 퍼플렉서티 115.22\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 1427[s] | 퍼플렉서티 149.03\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 1449[s] | 퍼플렉서티 144.77\n",
      "퍼플렉서티 평가 중 ...\n",
      "209 / 210\n",
      "검증 퍼플렉서티:  124.14334121669845\n",
      "--------------------------------------------------\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 1[s] | 퍼플렉서티 188.01\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 23[s] | 퍼플렉서티 129.47\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 44[s] | 퍼플렉서티 124.38\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 66[s] | 퍼플렉서티 118.42\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 88[s] | 퍼플렉서티 104.00\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 110[s] | 퍼플렉서티 99.58\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 132[s] | 퍼플렉서티 110.53\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 154[s] | 퍼플렉서티 121.32\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 176[s] | 퍼플렉서티 136.36\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 198[s] | 퍼플렉서티 143.78\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 220[s] | 퍼플렉서티 137.50\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 241[s] | 퍼플렉서티 133.96\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 263[s] | 퍼플렉서티 127.70\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 285[s] | 퍼플렉서티 136.78\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 307[s] | 퍼플렉서티 136.40\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 329[s] | 퍼플렉서티 115.69\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 351[s] | 퍼플렉서티 92.17\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 372[s] | 퍼플렉서티 129.35\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 394[s] | 퍼플렉서티 138.17\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 416[s] | 퍼플렉서티 110.95\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 438[s] | 퍼플렉서티 128.13\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 460[s] | 퍼플렉서티 110.23\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 482[s] | 퍼플렉서티 117.82\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 504[s] | 퍼플렉서티 117.31\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 526[s] | 퍼플렉서티 115.49\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 548[s] | 퍼플렉서티 127.86\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 570[s] | 퍼플렉서티 130.86\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 592[s] | 퍼플렉서티 134.89\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 613[s] | 퍼플렉서티 112.20\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 635[s] | 퍼플렉서티 104.09\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 657[s] | 퍼플렉서티 144.44\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 679[s] | 퍼플렉서티 135.95\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 701[s] | 퍼플렉서티 125.34\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 723[s] | 퍼플렉서티 115.79\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 745[s] | 퍼플렉서티 100.96\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 767[s] | 퍼플렉서티 118.01\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 789[s] | 퍼플렉서티 120.36\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 811[s] | 퍼플렉서티 104.20\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 833[s] | 퍼플렉서티 95.50\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 855[s] | 퍼플렉서티 102.60\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 877[s] | 퍼플렉서티 117.77\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 898[s] | 퍼플렉서티 116.33\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 920[s] | 퍼플렉서티 115.69\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 942[s] | 퍼플렉서티 113.63\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 964[s] | 퍼플렉서티 103.68\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 986[s] | 퍼플렉서티 134.04\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 1008[s] | 퍼플렉서티 116.34\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 1030[s] | 퍼플렉서티 122.73\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 1052[s] | 퍼플렉서티 133.28\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 1074[s] | 퍼플렉서티 124.71\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 1096[s] | 퍼플렉서티 107.45\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 1118[s] | 퍼플렉서티 126.53\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 1139[s] | 퍼플렉서티 111.89\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 1162[s] | 퍼플렉서티 105.20\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 1183[s] | 퍼플렉서티 87.12\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 1206[s] | 퍼플렉서티 90.18\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 1228[s] | 퍼플렉서티 125.27\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 1249[s] | 퍼플렉서티 117.71\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 1271[s] | 퍼플렉서티 100.05\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 1293[s] | 퍼플렉서티 108.60\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 1315[s] | 퍼플렉서티 90.87\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 1337[s] | 퍼플렉서티 89.46\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 1359[s] | 퍼플렉서티 107.54\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 1381[s] | 퍼플렉서티 101.69\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 1403[s] | 퍼플렉서티 101.97\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 1425[s] | 퍼플렉서티 130.73\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 1447[s] | 퍼플렉서티 125.59\n",
      "퍼플렉서티 평가 중 ...\n",
      "209 / 210\n",
      "검증 퍼플렉서티:  112.4029785499217\n",
      "--------------------------------------------------\n",
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  109.64915198512354\n"
     ]
    }
   ],
   "source": [
    "from common import config\n",
    "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
    "# ==============================================\n",
    "config.GPU = False\n",
    "# ==============================================\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity, to_gpu\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "if config.GPU:\n",
    "    corpus = to_gpu(corpus)\n",
    "    corpus_val = to_gpu(corpus_val)\n",
    "    corpus_test = to_gpu(corpus_test)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
    "                time_size=time_size, max_grad=max_grad)\n",
    "\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티: ', ppl)\n",
    "\n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "\n",
    "    model.reset_state()\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 그냥 LSTM과 개선된 LSTM을 비교하기 위하여 Epoch를 4로 설정하고 Train하는 중 이다.  \n",
    "실제 Epoch를 40으로하여 Trainning된 Model은 아래 링크에서 제공되고 있다.\n",
    "\n",
    "<a href=\"http://www.oreilly.co.jp/pub/9784873118369/BetterRnnlm.pkl\">BetterRnnlm.pkl 다운로드</a><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
