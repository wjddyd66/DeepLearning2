{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Term Dependency\n",
    "\n",
    "RNN의 장점 중 하나는 이전 정보를 현재 작업으로 연결할 수 있다는 점 이다.(Memory 사용)  \n",
    "하지만 이러한 장점으로 인한 단점이 생기게 되는 것이 **Long Term Dependency**이다.  \n",
    "첫번째의 예를 생각해보자.  \n",
    "우리가 현재 시점의 뭔가를 얻기 위해서 멀지 않은 최근의 정보만 필요로 할 때도 있다. 예를 들어 이전 단어들을 토대로 다음에 올 단어를 예측하는 언어 모델을 생각해 보자. 만약 우리가 \"the clouds are in the sky\"에서의 마지막 단어를 맞추고 싶다면, 저 문장 말고는 더 볼 필요도 없다. 마지막 단어는 sky일 것이 분명하다. 이 경우처럼 필요한 정보를 얻기 위한 시간 격차가 크지 않다면, RNN도 지난 정보를 바탕으로 학습할 수 있다.  \n",
    "\n",
    "<div><img src=\"https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/79.PNG\" height=\"250\" width=\"600\" /></div>\n",
    "<br>\n",
    "두번째의 예를 생각해보자.  \n",
    "하지만 반대로 더 많은 문맥을 필요로 하는 경우도 있다. \"I grew up in France... I speak fluent French\"라는 문단의 마지막 단어를 맞추고 싶다고 생각해보자. 최근 몇몇 단어를 봤을 때 아마도 언어에 대한 단어가 와야 될 것이라 생각할 수는 있지만, 어떤 나라 언어인지 알기 위해서는 프랑스에 대한 문맥을 훨씬 뒤에서 찾아봐야 한다. 이렇게 되면 필요한 정보를 얻기 위한 시간 격차는 굉장히 커지게 된다.  \n",
    "\n",
    "<div><img src=\"https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/80.PNG\" height=\"250\" width=\"600\" /></div>\n",
    "<br>\n",
    "\n",
    "위와같은 **Long Term Dependency**가 일어나는 이유를 아래 수식으로 살펴보자.  \n",
    "**Long Term Dependency**의 이유 2가지는 **vanishing 과 exploding gradients**이다.  \n",
    "\n",
    "\n",
    "위와 같은 이유는 **Activation Function을 tanh 함수를 사용한 것과 RNN의 특성상 모든 Hidden Layer가 같은 Weight를 공유하기 때문이다.**  \n",
    "\n",
    "**첫째, tanh**부터 살펴보게 되면 아래 식과 같이 나타낼 수 있다.  \n",
    "식: <span> $\\tanh(x) = {e^{x} - e^{-x} \\over e^{x} + e^{-x} } \\text{범위:[0,1]}$ </span><br>\n",
    "미분식: <span> $\\tanh\\prime(x) = 1-\\tanh^2(x) \\text{범위:[-1,1]}$ </span>\n",
    "<br>\n",
    "위와 같이 tanh 미분식이 -1 ~ 1의 범위를 가지므로 **Backpropagation에서 계속해서 값이 작아지는 vainshing문제가 발생하게 된다.**  \n",
    "\n",
    "**둘째, Hidden Layer가 같은 Weight를 공유**를 살펴보기 위하여 아래와 같은 코드 실행후 확인하였다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = 2   # 미니배치 크기\n",
    "H = 3   # 은닉 상태 벡터의 차원 수\n",
    "T = 20  # 시계열 데이터의 길이\n",
    "\n",
    "dh = np.ones((N, H))\n",
    "dh2 = np.ones((N, H))\n",
    "\n",
    "np.random.seed(3) # 재현할 수 있도록 난수의 시드 고정\n",
    "\n",
    "Wh = np.random.randn(H, H)\n",
    "Wh2 = np.random.randn(H, H) * 0.5\n",
    "\n",
    "norm_list = []\n",
    "norm_list2 = []\n",
    "for t in range(T):\n",
    "    dh = np.dot(dh, Wh.T)\n",
    "    dh2 = np.dot(dh2, Wh2.T)\n",
    "    \n",
    "    norm = np.sqrt(np.sum(dh**2)) / N\n",
    "    norm_list.append(norm)\n",
    "    \n",
    "    norm2 = np.sqrt(np.sum(dh2**2)) / N\n",
    "    norm_list2.append(norm2)\n",
    "\n",
    "\n",
    "#print(norm_list)\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('exploding gradients')\n",
    "plt.plot(np.arange(len(norm_list)), norm_list)\n",
    "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('norm')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('vanishing')\n",
    "plt.plot(np.arange(len(norm_list2)), norm_list2)\n",
    "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('norm2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight 인 Wh가 행렬이므로 행렬의 **'특이값'이 1이상일 경우 Exploding Gradients가 발생하고 '특이값'이 1이하인 경우 vanishing 문제가 발생하게 된다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploding Gradients\n",
    "Exploding Gradients의 해결방법으로 **Gradients Clipping**이 존재한다.  \n",
    "Gradients Clipping에대한 식은 아래와 같다.  \n",
    "<p>$if ||\\hat{g}|| \\ge threshold$</p>\n",
    "<p>$\\hat{g} =  \\frac{threshold}{||\\hat{g}||}\\hat{g}$</p>\n",
    "\n",
    "**Parameter 설명**  \n",
    "- <span>$\\hat{g}$ </span>: 사용하는 모든 매개변수의 기울기를 하나로 모은 것\n",
    "- <span>$||\\hat{g}||$ </span>: <span>$\\hat{g}$ </span>에 L2 norm 적용\n",
    "- <span>$threshold$ </span>: 문턱값\n",
    "\n",
    "위와같이 문턱값을 초과하면 문턱값으로 값을 대입하는 것으로 **Exploding Gradients**를 해결할 수 있는 것을 알 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: [5.44799518 3.47358019 5.65014947 5.43636298 3.88975196 9.74236234\n",
      " 2.28613427 5.28779157 4.54053003]\n",
      "after: [1.02768352 0.6552394  1.06581693 1.02548928 0.73374404 1.83775222\n",
      " 0.43124534 0.99746349 0.85650367]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate\n",
    "\n",
    "\n",
    "print('before:', dW1.flatten())\n",
    "clip_grads(grads, max_norm)\n",
    "print('after:', dW1.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "**Exploding Gradients은 Exploding Clipping로서 해결하여 vanishing 문제만 해결하면 된다.**  \n",
    "**vanishing 문제는 RNN에서 Gate를 추가한 LSTM의 형태로서 해결한다.**  \n",
    "\n",
    "RNN이 많이 사용되는 자연어 처리에서의 예를 들어보자.  \n",
    "먼저 텍스트 데이터는 이미지와는 다르게 서로 인접한 단어와 Discrete 하다는 특성을 갖는다. 이는 특정단어또는 문장이 주변부 단어 또는 문장과 연관성이 높을 수도 있고 낮을 수도 있음을 의미하며 생성형 요약을 구현하기 위해서는 문장의 길이가 길어져도 각각의 정보를 오래 기억할 수 있어야한다.  \n",
    "예를 들어“나는 학교에서 밥을 영희와 먹었다.”라는 문장에서 주어인 ‘나’와 ‘영희’는 위치적으로서로가장 떨어져 먼 거리에 위치해있다.  \n",
    "그런데 주어인 나와 영희의 관계가 가족이라면 나머지 단어들 ‘학교’, ‘밥’ 등 보다 ‘나’는 ‘영희’와 연관성이 더 높다.  \n",
    "신경망은 이 문장을 받아들일때 ‘나’ 라는 정보를 멀리 떨어진 ‘영희’ 라는 정보와 연관 지을 수있어야한다.  \n",
    "이러한 텍스트가 갖는 특징에대한 방안으로 Hidden Layer에 LSTM 을 사용하게 된다.  \n",
    "이러한 LSTM은 아래와 같은 그림으로서 표현할 수 있다.  \n",
    "\n",
    "<div><img src=\"http://i.imgur.com/jKodJ1u.png\" height=\"100%\" width=\"100%\" /></div>\n",
    "\n",
    "**LSTM 은 장기 의존성을 해결하기 위한 방안이다. LSTM 은 Forget gate와 Input gate가 특징으로 Forget gate는 과거 정보를 잊기 위한 게이트이다. Input gate 는 현재 정보를 기억하기 위한 게이트이다.**  \n",
    "두 게이트 모두 앞에 σ(시그모이드)를곱하여 0~1사이에값을 가지게 된다.  \n",
    "σ(시그모이드)를 곱한 Forget gate 와Input gate를 통해 과거의 정보와 현재의 정보를 얼마나 기억할 것인가를 정하여 장기 의존성의 문제를 해결한다.  \n",
    "이러한 Forget gate와 Input gate는 아래와 같은 그림으로서 나타낼 수 있다.  \n",
    "\n",
    "<div><img src=\"http://i.imgur.com/MPb3OvZ.png\" height=\"100%\" width=\"100%\" /></div>\n",
    "위의 Gate의 설명에서 비선형 효과를 주기 위하여 Activation Function의 종류를 2개 사용하였다.  \n",
    "각각의 Activation Function과 Parameter에 대해서 알아보자.  \n",
    "\n",
    "- σ(시그모이드): 0 ~ 1의 범위를 가지게 출력형태를 바꿔주며 데이터를 얼마만큼 통과시킬지를 정하는 비율\n",
    "- tanh(하이퍼 볼릭 탄젠트): -1 ~ 1의 범위를 가지게 출력형태를 바꿔주며 실질적인 정보의 비율\n",
    "- Output gate: <span>$o = \\sigma (W_{xh_o}x_t +W_{hh_o}h_{t-1} + b_{h_o})$</span>: 다음 시간의 Hidden Layer에서 얼만큼 중요한가를 나타내는 상수\n",
    "- Forget gate: <span>$f_t = \\sigma (W_{xh_f}x_t +W_{hh_f}h_{t-1} + b_{h_f})$</span>: 과거 정보를 잊기 위한 게이트(0 ~ 1사이의 값을 가지는 Scalar로서 얼만큼 잊을지 비율로서 표현)\n",
    "-  <span>$g$</span>: <span>$tanh(W_{xh_g}x_t +W_{hh_g}h_{t-1} + b_{h_g})$</span>: tanh를 사용하여 현재 LSTM Layer에서의 실질적인 정보의 비율\n",
    "- Input gate: <span>$i_t = \\sigma (W_{xh_i}x_t +W_{hh_i}h_{t-1} + b_{h_i})$</span>: 현재 정보를 기억하기 위한 게이트(0 ~ 1사이의 값을 가지는 Scalar로서 얼만큼 기억할 비율로서 표현)\n",
    "- <span>$c_t$</span>: 기억 셀로서 과거로부터 시각 t까지에 필요한 모든 정보가 저장된 Cell, <span>$c_t = f \\odot c_{t-1} + g \\odot i $</span>\n",
    "- <span>$h_t$</span>: <span>$o \\odot tanh(c_t)$</span>: Hidden Layer의 출력 o가 Sigmoid의 Output으로서 상수이므로 <span>$\\odot$ </span>사용\n",
    "\n",
    "위와 같은 LSTM의 망을 **Affine 변환**을 통해 빠르게 계산수행을 위해 아래와 같이 망을 최종적으로 구성한다.  \n",
    "<div><img src=\"http://i.imgur.com/73zzDsC.png\" height=\"100%\" width=\"100%\" /></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Wx: 입력 x에 대한 가중치 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        Wh: 은닉 상태 h에 대한 가장추 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        b: 편향（4개분의 편향이 담겨 있음）\n",
    "        '''\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "\n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "\n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "\n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "\n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "\n",
    "        dc_prev = ds * f\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**위의 결과로부터 BackPropagation 때 Vanishing 문제가 해결되는지 알아보자**  \n",
    "위의 식에서 <span>$c_t$</span>의 식을 Chain Rule을 사용하여 보자.  \n",
    "<p>$c_t = f_t \\odot c_{t-1} + g \\odot i$</p>\n",
    "<p>$\\frac{\\partial c_T}{\\partial c_t} = \\frac{\\partial c_T}{\\partial c_{T-1}} \\frac{\\partial c_{T-1}}{\\partial c_{T-2}} ... \\frac{\\partial c_{t+1}}{\\partial c_t}$</p>\n",
    "<p>$\\frac{\\partial c_T}{\\partial c_{T-1}} = f_T, \\frac{\\partial c_{T-1}}{\\partial c_{T-2}} = f_{T-1}, ...,  \\frac{\\partial c_{t+1}}{\\partial c_t} = f_{t+1}$</p>\n",
    "<p>$\\frac{\\partial c_T}{\\partial c_t} = \\prod_{i=t+1}^T f_i$</p>\n",
    "위의 식에서 f는 sigmoid의 output의 값으로서 1에 가까울수록 과거의 정보를 많이 기억한다는 것이고 Backpropagation에서 Loss의 값은 0 에 가깝게 될 것이고 Optimizer로서 SGD사용시 조금 변화하는 것을 알 수 있다.  \n",
    "\n",
    "각각의 Gate에 대하여 Backpropagation의 결과는 아래와 같다.  \n",
    "<div><img src=\"https://drive.google.com/uc?id=13jvu-aT2SgiRsVHhLHVU9jXloiLHQgt1\" height=\"100%\" width=\"100%\" /></div>\n",
    "위와 같은 그림에서 중요한 점은 <span>$H_T$</span>는 Affine 변환을 통하여 한번에 더해주는 과정을 거쳤으므로 Backpropagation에서도 기울기를 합쳐서 보내는 과정을 거쳐야 된다는 것 이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time LSTM\n",
    "Time LSTM이란 T개분의 시계열 데이터를 한꺼번에 처리하는 계층이다.  \n",
    "앞선 POST에서의 Time RNN과 다른것은 하나의 Layer를 RNN대시 LSTM으로 하였고 은닉상태와 기억 셀 2개의 값을 인스턴스 변수로 유지한다는 것 이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 정의한 **Time LSTM**을 활용하여 Softmax직전까지의 Rnnlm을 구성하는 코드이다.  \n",
    "즉, Embedding -> Time LSTM -> Time Affine까지의 계층 구현이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 구현한 Rnnlm을 Train하는 Code이다.  \n",
    "이전 Post에서의 Simple Rnnlm과 다른점은 **Exploding Gradients을 해결하기 위하여 Exploding Clipping을 사용한 것 이다.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 10002.11\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 2612.64\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 7[s] | 퍼플렉서티 1253.93\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 11[s] | 퍼플렉서티 977.90\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 15[s] | 퍼플렉서티 782.97\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 19[s] | 퍼플렉서티 640.05\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 23[s] | 퍼플렉서티 657.03\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 27[s] | 퍼플렉서티 595.01\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 31[s] | 퍼플렉서티 587.60\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 35[s] | 퍼플렉서티 589.98\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 39[s] | 퍼플렉서티 504.04\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 43[s] | 퍼플렉서티 487.82\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 47[s] | 퍼플렉서티 441.64\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 51[s] | 퍼플렉서티 453.01\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 55[s] | 퍼플렉서티 448.88\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 59[s] | 퍼플렉서티 385.96\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 62[s] | 퍼플렉서티 341.99\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 66[s] | 퍼플렉서티 401.90\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 70[s] | 퍼플렉서티 400.60\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 74[s] | 퍼플렉서티 337.25\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 78[s] | 퍼플렉서티 348.49\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 82[s] | 퍼플렉서티 337.72\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 86[s] | 퍼플렉서티 322.69\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 90[s] | 퍼플렉서티 322.98\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 94[s] | 퍼플렉서티 297.17\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 98[s] | 퍼플렉서티 310.30\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 102[s] | 퍼플렉서티 300.94\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 106[s] | 퍼플렉서티 316.70\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 110[s] | 퍼플렉서티 282.51\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 114[s] | 퍼플렉서티 256.36\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 117[s] | 퍼플렉서티 332.35\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 121[s] | 퍼플렉서티 312.07\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 125[s] | 퍼플렉서티 279.08\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 129[s] | 퍼플렉서티 265.73\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 133[s] | 퍼플렉서티 225.37\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 137[s] | 퍼플렉서티 248.23\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 141[s] | 퍼플렉서티 257.95\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 145[s] | 퍼플렉서티 216.85\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 148[s] | 퍼플렉서티 232.17\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 152[s] | 퍼플렉서티 212.84\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 156[s] | 퍼플렉서티 240.15\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 160[s] | 퍼플렉서티 221.89\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 164[s] | 퍼플렉서티 224.21\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 168[s] | 퍼플렉서티 218.75\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 171[s] | 퍼플렉서티 201.84\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 175[s] | 퍼플렉서티 252.01\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 179[s] | 퍼플렉서티 224.91\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 183[s] | 퍼플렉서티 226.88\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 187[s] | 퍼플렉서티 241.68\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 191[s] | 퍼플렉서티 227.96\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 195[s] | 퍼플렉서티 191.41\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 198[s] | 퍼플렉서티 224.38\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 202[s] | 퍼플렉서티 205.30\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 206[s] | 퍼플렉서티 193.62\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 210[s] | 퍼플렉서티 166.77\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 214[s] | 퍼플렉서티 187.85\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 217[s] | 퍼플렉서티 226.06\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 221[s] | 퍼플렉서티 206.72\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 225[s] | 퍼플렉서티 195.24\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 229[s] | 퍼플렉서티 188.03\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 233[s] | 퍼플렉서티 161.95\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 237[s] | 퍼플렉서티 157.26\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 241[s] | 퍼플렉서티 184.21\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 245[s] | 퍼플렉서티 169.27\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 248[s] | 퍼플렉서티 176.27\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 252[s] | 퍼플렉서티 218.85\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 257[s] | 퍼플렉서티 208.74\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 258[s] | 퍼플렉서티 222.52\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 262[s] | 퍼플렉서티 201.90\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 266[s] | 퍼플렉서티 188.17\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 270[s] | 퍼플렉서티 172.98\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 274[s] | 퍼플렉서티 156.18\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 278[s] | 퍼플렉서티 149.92\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 282[s] | 퍼플렉서티 157.67\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 285[s] | 퍼플렉서티 176.64\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 289[s] | 퍼플렉서티 188.88\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 293[s] | 퍼플렉서티 198.10\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 297[s] | 퍼플렉서티 183.06\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 301[s] | 퍼플렉서티 181.69\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 305[s] | 퍼플렉서티 174.23\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 309[s] | 퍼플렉서티 184.09\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 313[s] | 퍼플렉서티 184.19\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 317[s] | 퍼플렉서티 163.63\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 321[s] | 퍼플렉서티 136.47\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 325[s] | 퍼플렉서티 171.07\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 329[s] | 퍼플렉서티 195.36\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 333[s] | 퍼플렉서티 151.19\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 337[s] | 퍼플렉서티 165.64\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 341[s] | 퍼플렉서티 152.26\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 345[s] | 퍼플렉서티 160.74\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 349[s] | 퍼플렉서티 155.27\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 353[s] | 퍼플렉서티 154.11\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 357[s] | 퍼플렉서티 168.13\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 360[s] | 퍼플렉서티 172.89\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 364[s] | 퍼플렉서티 174.48\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 368[s] | 퍼플렉서티 151.60\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 372[s] | 퍼플렉서티 138.50\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 376[s] | 퍼플렉서티 188.00\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 379[s] | 퍼플렉서티 180.62\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 383[s] | 퍼플렉서티 163.49\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 387[s] | 퍼플렉서티 152.87\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 391[s] | 퍼플렉서티 126.80\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 395[s] | 퍼플렉서티 149.43\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 398[s] | 퍼플렉서티 158.55\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 402[s] | 퍼플렉서티 131.80\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 406[s] | 퍼플렉서티 128.58\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 410[s] | 퍼플렉서티 135.00\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 414[s] | 퍼플렉서티 145.73\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 417[s] | 퍼플렉서티 142.97\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 421[s] | 퍼플렉서티 142.50\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 425[s] | 퍼플렉서티 145.37\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 429[s] | 퍼플렉서티 128.75\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 432[s] | 퍼플렉서티 165.92\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 436[s] | 퍼플렉서티 146.13\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 440[s] | 퍼플렉서티 153.14\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 444[s] | 퍼플렉서티 163.35\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 448[s] | 퍼플렉서티 154.18\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 452[s] | 퍼플렉서티 131.02\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 456[s] | 퍼플렉서티 156.54\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 460[s] | 퍼플렉서티 141.10\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 463[s] | 퍼플렉서티 127.02\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 467[s] | 퍼플렉서티 110.87\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 471[s] | 퍼플렉서티 118.79\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 475[s] | 퍼플렉서티 150.53\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 479[s] | 퍼플렉서티 141.00\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 483[s] | 퍼플렉서티 131.55\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 487[s] | 퍼플렉서티 132.01\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 491[s] | 퍼플렉서티 111.17\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 495[s] | 퍼플렉서티 108.55\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 499[s] | 퍼플렉서티 129.98\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 503[s] | 퍼플렉서티 122.20\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 506[s] | 퍼플렉서티 122.16\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 510[s] | 퍼플렉서티 157.19\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 514[s] | 퍼플렉서티 153.15\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 515[s] | 퍼플렉서티 160.96\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 519[s] | 퍼플렉서티 144.13\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 523[s] | 퍼플렉서티 135.85\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 527[s] | 퍼플렉서티 126.47\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 530[s] | 퍼플렉서티 115.98\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 534[s] | 퍼플렉서티 104.72\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 538[s] | 퍼플렉서티 115.11\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 542[s] | 퍼플렉서티 126.02\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 546[s] | 퍼플렉서티 141.58\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 550[s] | 퍼플렉서티 151.07\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 553[s] | 퍼플렉서티 140.30\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 557[s] | 퍼플렉서티 138.86\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 561[s] | 퍼플렉서티 133.45\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 565[s] | 퍼플렉서티 138.82\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 568[s] | 퍼플렉서티 140.75\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 572[s] | 퍼플렉서티 123.58\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 576[s] | 퍼플렉서티 101.47\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 580[s] | 퍼플렉서티 125.12\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 584[s] | 퍼플렉서티 151.16\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 587[s] | 퍼플렉서티 113.31\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 591[s] | 퍼플렉서티 127.89\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 595[s] | 퍼플렉서티 113.06\n",
      "| 에폭 3 |  반복 441 / 1327 | 시간 599[s] | 퍼플렉서티 122.34\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 603[s] | 퍼플렉서티 116.07\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 607[s] | 퍼플렉서티 118.93\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 610[s] | 퍼플렉서티 128.21\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 614[s] | 퍼플렉서티 137.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 3 |  반복 541 / 1327 | 시간 618[s] | 퍼플렉서티 135.76\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 622[s] | 퍼플렉서티 117.65\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 626[s] | 퍼플렉서티 105.81\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 629[s] | 퍼플렉서티 149.75\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 633[s] | 퍼플렉서티 142.67\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 637[s] | 퍼플렉서티 129.89\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 641[s] | 퍼플렉서티 118.54\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 645[s] | 퍼플렉서티 98.89\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 648[s] | 퍼플렉서티 117.98\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 652[s] | 퍼플렉서티 125.60\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 656[s] | 퍼플렉서티 106.45\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 660[s] | 퍼플렉서티 101.67\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 664[s] | 퍼플렉서티 103.33\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 667[s] | 퍼플렉서티 116.13\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 671[s] | 퍼플렉서티 116.93\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 675[s] | 퍼플렉서티 114.14\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 679[s] | 퍼플렉서티 120.66\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 683[s] | 퍼플렉서티 106.21\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 686[s] | 퍼플렉서티 132.95\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 690[s] | 퍼플렉서티 118.82\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 694[s] | 퍼플렉서티 126.14\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 698[s] | 퍼플렉서티 131.81\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 702[s] | 퍼플렉서티 124.50\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 705[s] | 퍼플렉서티 108.88\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 709[s] | 퍼플렉서티 129.18\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 713[s] | 퍼플렉서티 118.20\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 717[s] | 퍼플렉서티 102.81\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 721[s] | 퍼플렉서티 89.43\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 724[s] | 퍼플렉서티 95.23\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 728[s] | 퍼플렉서티 120.78\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 732[s] | 퍼플렉서티 114.62\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 736[s] | 퍼플렉서티 105.67\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 740[s] | 퍼플렉서티 109.79\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 743[s] | 퍼플렉서티 93.74\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 747[s] | 퍼플렉서티 88.12\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 751[s] | 퍼플렉서티 106.11\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 755[s] | 퍼플렉서티 104.03\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 758[s] | 퍼플렉서티 100.80\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 762[s] | 퍼플렉서티 129.26\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 766[s] | 퍼플렉서티 127.55\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 767[s] | 퍼플렉서티 133.37\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 771[s] | 퍼플렉서티 121.58\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 775[s] | 퍼플렉서티 107.51\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 779[s] | 퍼플렉서티 108.22\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 783[s] | 퍼플렉서티 95.27\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 787[s] | 퍼플렉서티 85.92\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 791[s] | 퍼플렉서티 95.33\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 794[s] | 퍼플렉서티 103.89\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 798[s] | 퍼플렉서티 116.51\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 802[s] | 퍼플렉서티 129.47\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 806[s] | 퍼플렉서티 120.25\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 810[s] | 퍼플렉서티 121.27\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 814[s] | 퍼플렉서티 115.09\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 818[s] | 퍼플렉서티 114.95\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 822[s] | 퍼플렉서티 120.56\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 826[s] | 퍼플렉서티 104.30\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 830[s] | 퍼플렉서티 83.48\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 833[s] | 퍼플렉서티 100.67\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 837[s] | 퍼플렉서티 127.79\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 841[s] | 퍼플렉서티 95.63\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 845[s] | 퍼플렉서티 108.21\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 849[s] | 퍼플렉서티 93.33\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 853[s] | 퍼플렉서티 102.78\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 857[s] | 퍼플렉서티 98.19\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 861[s] | 퍼플렉서티 102.86\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 864[s] | 퍼플렉서티 107.67\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 868[s] | 퍼플렉서티 116.90\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 872[s] | 퍼플렉서티 112.60\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 876[s] | 퍼플렉서티 102.04\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 880[s] | 퍼플렉서티 89.59\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 884[s] | 퍼플렉서티 127.46\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 888[s] | 퍼플렉서티 121.93\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 891[s] | 퍼플렉서티 111.10\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 895[s] | 퍼플렉서티 101.67\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 899[s] | 퍼플렉서티 84.77\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 903[s] | 퍼플렉서티 102.30\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 907[s] | 퍼플렉서티 106.75\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 911[s] | 퍼플렉서티 94.69\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 915[s] | 퍼플렉서티 87.02\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 918[s] | 퍼플렉서티 87.80\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 922[s] | 퍼플렉서티 98.88\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 926[s] | 퍼플렉서티 103.16\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 930[s] | 퍼플렉서티 98.23\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 933[s] | 퍼플렉서티 104.74\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 937[s] | 퍼플렉서티 91.36\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 941[s] | 퍼플렉서티 116.61\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 945[s] | 퍼플렉서티 103.64\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 949[s] | 퍼플렉서티 112.09\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 952[s] | 퍼플렉서티 112.60\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 956[s] | 퍼플렉서티 106.87\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 960[s] | 퍼플렉서티 97.35\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 964[s] | 퍼플렉서티 113.81\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 968[s] | 퍼플렉서티 103.06\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 971[s] | 퍼플렉서티 89.07\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 975[s] | 퍼플렉서티 79.22\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 979[s] | 퍼플렉서티 80.43\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 983[s] | 퍼플렉서티 102.97\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 987[s] | 퍼플렉서티 99.40\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 990[s] | 퍼플렉서티 91.46\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 994[s] | 퍼플렉서티 94.33\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 998[s] | 퍼플렉서티 83.09\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 1002[s] | 퍼플렉서티 75.51\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 1006[s] | 퍼플렉서티 91.76\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 1009[s] | 퍼플렉서티 92.87\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 1013[s] | 퍼플렉서티 89.60\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 1017[s] | 퍼플렉서티 111.22\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 1021[s] | 퍼플렉서티 109.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  134.85544110439733\n"
     ]
    }
   ],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 35     # RNN을 펼치는 크기\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# 모델 생성\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 기울기 클리핑을 적용하여 학습\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n",
    "            eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "\n",
    "# 매개변수 저장\n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 Time LSTM에서 여러가지 기법을 사용하여 좀 더 Model의 퍼블렉서티의 값이 낮아지게 하는 것을 목표로 한다.  \n",
    "\n",
    "**1. Layer Depth 증가**  \n",
    "Layer Depth가 증가하게 되면 비선형성이 더욱 증가되어 Data를 예측하는 성능이 높아지게 된다.  \n",
    "하지만 이러한 Layer Depth를 증가시키면 크게 2가지의 문제가 발생하게 된다.  \n",
    "1. Layer Depth가 깊어질수록 Hyper Parameter의 수가 증가하게 되며, 학습에 사용할 데이터 양이 제한적일 경우 Overfitting에 빠질 위험이 있다.\n",
    "2. Layer Depth가 증가하게 되면 연산량이 늘어나게 된다.\n",
    "\n",
    "현재 사용하는 PTB데이터셋의 언어 모델에서는 LSTM의 층 수는 2~4정도일때 좋은 결과를 만든다고 하여 2층으로 선정하였다.  \n",
    "\n",
    "**2. Dropout**  \n",
    "DropOut Dropout은 Overfitting을 막기위한 방법으로 뉴럴 네트워크가 학습중일때, 랜덤하게 뉴런을 꺼서 학습함으로써, 학습이 학습용 데이터로 치우치는 현상을 막아준다.  \n",
    "<a href=\"https://wjddyd66.github.io/dl/2019/08/31/NeuralNetwork-(5)-Others.html\">Dropout의 자세한 내용</a><br>\n",
    "\n",
    "**LSTM 의 경우 Dropout의 위치가 중요하게 된다. Dropout의 위치에 따라서 timestep의 정보가 지워져서 시계열 데이터를 사용하는데 어려움을 겪을 수 있기 때문이다.**  \n",
    "\n",
    "따라서 LSTM에서 권장하는 Dropout의 위치는 다음과 같다.  \n",
    "<div><img src=\"https://nmhkahn.github.io/assets/RNN-Reg/p1-dropout.png\" height=\"250\" width=\"600\" /></div>\n",
    "\n",
    "위 그림에서 점선은 dropout이 적용된 연결이고 실선은 dropout이 적용이 되지 않은 것이다. 제시한 방법을 곱씹어보면 이전 timestep에서 온 정보는 dropout 하지 말고, **현재 timestep에서 들어온 입력값 혹은 이전 레이어의 값만 dropout** 하는 의미이다.  \n",
    "현재 timestep에서 이전 레이어인 <span>$$h_t^{l-1}$$</span>에 dropout을 적용했는데 과거 timestep의 정보를 지우지 않게 하기 위해 recurrent한 연결 (과거 timestep)에 dropout을 적용하지 않은 것으로 보인다. 다시 정리하면, 일반적인 dropout을 적용한다면 먼 과거의 정보를 잃어버려 학습하는데 어려움을 갖지만, **non-recurrent한 연결만 dropout을 적용하면 과거 중요 정보를 희생하지 않아도 regularization을 사용**할 수 있다.\n",
    "\n",
    "위의 내용을 정리하면 즉, LSTM의 결과 <span>$$c_t^{l}, h_t^{l}$$</span>에서 이전 timestep의 내용을 가지고 있는 <span>$$c_t^{l}$$</span>에 dropout을 적용하게 되면 timestep의 정보가 지워질 수 있다는 것 이다.  \n",
    "\n",
    "**3. 가중치 공유(Weight Tying)**  \n",
    "**Weight Tying** 란 입력-임베딩 레이어와 출력 과 softmax 레이어 사이의 가중치 매트릭스 공유 즉, 두 개의 가중치 행렬을 사용하는 대신 하나의 가중치 행렬 만 사용하는 방법이다.  \n",
    "즉 Embedding을 Encoding이라고 생각하게 되면, Encoding과 Decoding의 방식을 같게한다고 생각할 수 있다.  \n",
    "실제로 가중치 공유를 하게되면 다음과 같은 2가지 장점을 생각할 수 있다.\n",
    "1. Hyper Parameter의 수가 감소하게 되여 Overfitting에 빠질 위험 감소\n",
    "2. Update해야할 Weight감소로 인하여 학습 속도 개선\n",
    "\n",
    "\n",
    "\n",
    "**실제 구현**  \n",
    "- LSTM 계층의 다층화(2층)\n",
    "- Dropout 사용\n",
    "- 가중치 공유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "from common.np import *  # import numpy as np\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650,\n",
    "                 hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)  # weight tying!!\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**결과 확인**  \n",
    "이전 Train과 달리 검증 데이터로 퍼플렉서티를 평가하고, 그 값이 나빠졌을 경우에만 학습률을 낮추는 방법으로 Train을 하였다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 1[s] | 퍼플렉서티 10000.24\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 25[s] | 퍼플렉서티 3268.14\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 50[s] | 퍼플렉서티 1861.89\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 75[s] | 퍼플렉서티 1299.86\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 100[s] | 퍼플렉서티 1099.30\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 125[s] | 퍼플렉서티 833.11\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 149[s] | 퍼플렉서티 789.12\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 174[s] | 퍼플렉서티 695.42\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 202[s] | 퍼플렉서티 683.55\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 228[s] | 퍼플렉서티 673.48\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 253[s] | 퍼플렉서티 586.21\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 279[s] | 퍼플렉서티 577.16\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 304[s] | 퍼플렉서티 511.99\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 329[s] | 퍼플렉서티 536.13\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 354[s] | 퍼플렉서티 523.40\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 379[s] | 퍼플렉서티 452.04\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 404[s] | 퍼플렉서티 389.26\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 430[s] | 퍼플렉서티 443.76\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 454[s] | 퍼플렉서티 467.76\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 479[s] | 퍼플렉서티 382.34\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 504[s] | 퍼플렉서티 399.99\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 529[s] | 퍼플렉서티 392.48\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 554[s] | 퍼플렉서티 374.61\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 579[s] | 퍼플렉서티 370.61\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 604[s] | 퍼플렉서티 339.15\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 629[s] | 퍼플렉서티 358.24\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 654[s] | 퍼플렉서티 340.19\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 679[s] | 퍼플렉서티 359.60\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 705[s] | 퍼플렉서티 325.89\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 730[s] | 퍼플렉서티 288.28\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 755[s] | 퍼플렉서티 381.05\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 780[s] | 퍼플렉서티 342.74\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 805[s] | 퍼플렉서티 315.39\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 830[s] | 퍼플렉서티 299.80\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 855[s] | 퍼플렉서티 257.15\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 880[s] | 퍼플렉서티 276.92\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 906[s] | 퍼플렉서티 286.93\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 931[s] | 퍼플렉서티 247.60\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 956[s] | 퍼플렉서티 261.24\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 981[s] | 퍼플렉서티 243.91\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 1007[s] | 퍼플렉서티 269.75\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 1031[s] | 퍼플렉서티 251.92\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 1056[s] | 퍼플렉서티 254.73\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 1081[s] | 퍼플렉서티 250.93\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 1106[s] | 퍼플렉서티 230.84\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 1131[s] | 퍼플렉서티 282.08\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 1156[s] | 퍼플렉서티 259.31\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 1180[s] | 퍼플렉서티 256.70\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 1205[s] | 퍼플렉서티 276.36\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 1230[s] | 퍼플렉서티 256.35\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 1255[s] | 퍼플렉서티 215.04\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 1280[s] | 퍼플렉서티 251.77\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 1305[s] | 퍼플렉서티 232.88\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 1330[s] | 퍼플렉서티 219.14\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 1355[s] | 퍼플렉서티 189.35\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 1380[s] | 퍼플렉서티 216.69\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 1406[s] | 퍼플렉서티 254.03\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 1432[s] | 퍼플렉서티 231.26\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 1457[s] | 퍼플렉서티 220.55\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 1482[s] | 퍼플렉서티 210.19\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 1507[s] | 퍼플렉서티 178.92\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 1532[s] | 퍼플렉서티 179.82\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 1558[s] | 퍼플렉서티 208.25\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 1583[s] | 퍼플렉서티 193.18\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 1608[s] | 퍼플렉서티 198.08\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 1633[s] | 퍼플렉서티 248.73\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 1658[s] | 퍼플렉서티 232.99\n",
      "퍼플렉서티 평가 중 ...\n",
      "209 / 210\n",
      "검증 퍼플렉서티:  198.15944247339417\n",
      "--------------------------------------------------\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 1[s] | 퍼플렉서티 291.25\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 26[s] | 퍼플렉서티 230.18\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 51[s] | 퍼플렉서티 212.38\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 76[s] | 퍼플렉서티 196.14\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 102[s] | 퍼플렉서티 180.26\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 127[s] | 퍼플렉서티 169.25\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 152[s] | 퍼플렉서티 183.08\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 177[s] | 퍼플렉서티 200.20\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 202[s] | 퍼플렉서티 216.40\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 227[s] | 퍼플렉서티 223.49\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 252[s] | 퍼플렉서티 207.51\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 277[s] | 퍼플렉서티 205.18\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 303[s] | 퍼플렉서티 196.51\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 328[s] | 퍼플렉서티 214.97\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 355[s] | 퍼플렉서티 203.92\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 380[s] | 퍼플렉서티 186.65\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 405[s] | 퍼플렉서티 155.34\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 430[s] | 퍼플렉서티 199.72\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 455[s] | 퍼플렉서티 215.51\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 479[s] | 퍼플렉서티 173.43\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 504[s] | 퍼플렉서티 194.71\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 529[s] | 퍼플렉서티 173.83\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 554[s] | 퍼플렉서티 179.14\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 580[s] | 퍼플렉서티 183.31\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 605[s] | 퍼플렉서티 176.77\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 630[s] | 퍼플렉서티 191.26\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 654[s] | 퍼플렉서티 191.78\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 680[s] | 퍼플렉서티 200.89\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 705[s] | 퍼플렉서티 171.77\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 729[s] | 퍼플렉서티 158.07\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 755[s] | 퍼플렉서티 214.89\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 780[s] | 퍼플렉서티 203.30\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 805[s] | 퍼플렉서티 185.92\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 830[s] | 퍼플렉서티 171.55\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 856[s] | 퍼플렉서티 145.78\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 881[s] | 퍼플렉서티 169.11\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 907[s] | 퍼플렉서티 176.37\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 932[s] | 퍼플렉서티 150.53\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 957[s] | 퍼플렉서티 149.82\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 983[s] | 퍼플렉서티 148.77\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 1009[s] | 퍼플렉서티 169.81\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 1034[s] | 퍼플렉서티 163.46\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 1059[s] | 퍼플렉서티 162.90\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 1084[s] | 퍼플렉서티 160.23\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 1111[s] | 퍼플렉서티 147.71\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 1133[s] | 퍼플렉서티 190.13\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 1155[s] | 퍼플렉서티 166.38\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 1176[s] | 퍼플렉서티 169.69\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 1198[s] | 퍼플렉서티 183.56\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 1220[s] | 퍼플렉서티 174.32\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 1243[s] | 퍼플렉서티 148.24\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 1265[s] | 퍼플렉서티 176.67\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 1288[s] | 퍼플렉서티 158.88\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 1309[s] | 퍼플렉서티 148.02\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 1331[s] | 퍼플렉서티 123.96\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 1353[s] | 퍼플렉서티 137.09\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 1374[s] | 퍼플렉서티 171.51\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 1396[s] | 퍼플렉서티 161.50\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 1418[s] | 퍼플렉서티 147.90\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 1440[s] | 퍼플렉서티 148.12\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 1461[s] | 퍼플렉서티 125.89\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 1483[s] | 퍼플렉서티 124.39\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 1505[s] | 퍼플렉서티 147.86\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 1527[s] | 퍼플렉서티 138.04\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 1549[s] | 퍼플렉서티 140.43\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 1571[s] | 퍼플렉서티 178.66\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 1593[s] | 퍼플렉서티 171.01\n",
      "퍼플렉서티 평가 중 ...\n",
      "209 / 210\n",
      "검증 퍼플렉서티:  145.69148880984812\n",
      "--------------------------------------------------\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 1[s] | 퍼플렉서티 218.46\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 22[s] | 퍼플렉서티 161.48\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 44[s] | 퍼플렉서티 152.46\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 66[s] | 퍼플렉서티 143.14\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 88[s] | 퍼플렉서티 129.10\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 110[s] | 퍼플렉서티 121.11\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 132[s] | 퍼플렉서티 134.52\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 154[s] | 퍼플렉서티 146.92\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 176[s] | 퍼플렉서티 162.48\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 198[s] | 퍼플렉서티 167.63\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 219[s] | 퍼플렉서티 160.02\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 241[s] | 퍼플렉서티 156.03\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 263[s] | 퍼플렉서티 151.71\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 285[s] | 퍼플렉서티 163.17\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 307[s] | 퍼플렉서티 158.27\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 331[s] | 퍼플렉서티 140.11\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 353[s] | 퍼플렉서티 112.00\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 375[s] | 퍼플렉서티 151.51\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 397[s] | 퍼플렉서티 164.86\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 419[s] | 퍼플렉서티 132.80\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 441[s] | 퍼플렉서티 149.10\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 463[s] | 퍼플렉서티 130.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 3 |  반복 441 / 1327 | 시간 485[s] | 퍼플렉서티 139.50\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 507[s] | 퍼플렉서티 138.08\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 529[s] | 퍼플렉서티 135.04\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 551[s] | 퍼플렉서티 149.60\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 573[s] | 퍼플렉서티 153.00\n",
      "| 에폭 3 |  반복 541 / 1327 | 시간 595[s] | 퍼플렉서티 158.19\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 617[s] | 퍼플렉서티 133.15\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 639[s] | 퍼플렉서티 121.91\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 661[s] | 퍼플렉서티 170.14\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 683[s] | 퍼플렉서티 159.96\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 705[s] | 퍼플렉서티 145.27\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 727[s] | 퍼플렉서티 136.45\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 749[s] | 퍼플렉서티 116.32\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 771[s] | 퍼플렉서티 137.36\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 793[s] | 퍼플렉서티 140.68\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 815[s] | 퍼플렉서티 119.37\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 837[s] | 퍼플렉서티 115.40\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 859[s] | 퍼플렉서티 119.24\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 881[s] | 퍼플렉서티 139.16\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 902[s] | 퍼플렉서티 132.44\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 924[s] | 퍼플렉서티 134.07\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 946[s] | 퍼플렉서티 130.83\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 968[s] | 퍼플렉서티 119.52\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 990[s] | 퍼플렉서티 152.16\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 1012[s] | 퍼플렉서티 135.46\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 1034[s] | 퍼플렉서티 139.65\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 1056[s] | 퍼플렉서티 151.60\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 1077[s] | 퍼플렉서티 142.64\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 1099[s] | 퍼플렉서티 122.82\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 1121[s] | 퍼플렉서티 146.63\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 1143[s] | 퍼플렉서티 129.48\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 1165[s] | 퍼플렉서티 121.05\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 1187[s] | 퍼플렉서티 100.48\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 1209[s] | 퍼플렉서티 106.95\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 1230[s] | 퍼플렉서티 139.90\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 1252[s] | 퍼플렉서티 134.08\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 1274[s] | 퍼플렉서티 117.24\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 1296[s] | 퍼플렉서티 122.86\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 1318[s] | 퍼플렉서티 103.40\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 1340[s] | 퍼플렉서티 103.80\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 1361[s] | 퍼플렉서티 122.46\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 1383[s] | 퍼플렉서티 115.21\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 1405[s] | 퍼플렉서티 115.22\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 1427[s] | 퍼플렉서티 149.03\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 1449[s] | 퍼플렉서티 144.77\n",
      "퍼플렉서티 평가 중 ...\n",
      "209 / 210\n",
      "검증 퍼플렉서티:  124.14334121669845\n",
      "--------------------------------------------------\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 1[s] | 퍼플렉서티 188.01\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 23[s] | 퍼플렉서티 129.47\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 44[s] | 퍼플렉서티 124.38\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 66[s] | 퍼플렉서티 118.42\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 88[s] | 퍼플렉서티 104.00\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 110[s] | 퍼플렉서티 99.58\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 132[s] | 퍼플렉서티 110.53\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 154[s] | 퍼플렉서티 121.32\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 176[s] | 퍼플렉서티 136.36\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 198[s] | 퍼플렉서티 143.78\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 220[s] | 퍼플렉서티 137.50\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 241[s] | 퍼플렉서티 133.96\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 263[s] | 퍼플렉서티 127.70\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 285[s] | 퍼플렉서티 136.78\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 307[s] | 퍼플렉서티 136.40\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 329[s] | 퍼플렉서티 115.69\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 351[s] | 퍼플렉서티 92.17\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 372[s] | 퍼플렉서티 129.35\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 394[s] | 퍼플렉서티 138.17\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 416[s] | 퍼플렉서티 110.95\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 438[s] | 퍼플렉서티 128.13\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 460[s] | 퍼플렉서티 110.23\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 482[s] | 퍼플렉서티 117.82\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 504[s] | 퍼플렉서티 117.31\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 526[s] | 퍼플렉서티 115.49\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 548[s] | 퍼플렉서티 127.86\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 570[s] | 퍼플렉서티 130.86\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 592[s] | 퍼플렉서티 134.89\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 613[s] | 퍼플렉서티 112.20\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 635[s] | 퍼플렉서티 104.09\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 657[s] | 퍼플렉서티 144.44\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 679[s] | 퍼플렉서티 135.95\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 701[s] | 퍼플렉서티 125.34\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 723[s] | 퍼플렉서티 115.79\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 745[s] | 퍼플렉서티 100.96\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 767[s] | 퍼플렉서티 118.01\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 789[s] | 퍼플렉서티 120.36\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 811[s] | 퍼플렉서티 104.20\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 833[s] | 퍼플렉서티 95.50\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 855[s] | 퍼플렉서티 102.60\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 877[s] | 퍼플렉서티 117.77\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 898[s] | 퍼플렉서티 116.33\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 920[s] | 퍼플렉서티 115.69\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 942[s] | 퍼플렉서티 113.63\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 964[s] | 퍼플렉서티 103.68\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 986[s] | 퍼플렉서티 134.04\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 1008[s] | 퍼플렉서티 116.34\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 1030[s] | 퍼플렉서티 122.73\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 1052[s] | 퍼플렉서티 133.28\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 1074[s] | 퍼플렉서티 124.71\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 1096[s] | 퍼플렉서티 107.45\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 1118[s] | 퍼플렉서티 126.53\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 1139[s] | 퍼플렉서티 111.89\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 1162[s] | 퍼플렉서티 105.20\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 1183[s] | 퍼플렉서티 87.12\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 1206[s] | 퍼플렉서티 90.18\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 1228[s] | 퍼플렉서티 125.27\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 1249[s] | 퍼플렉서티 117.71\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 1271[s] | 퍼플렉서티 100.05\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 1293[s] | 퍼플렉서티 108.60\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 1315[s] | 퍼플렉서티 90.87\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 1337[s] | 퍼플렉서티 89.46\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 1359[s] | 퍼플렉서티 107.54\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 1381[s] | 퍼플렉서티 101.69\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 1403[s] | 퍼플렉서티 101.97\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 1425[s] | 퍼플렉서티 130.73\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 1447[s] | 퍼플렉서티 125.59\n",
      "퍼플렉서티 평가 중 ...\n",
      "209 / 210\n",
      "검증 퍼플렉서티:  112.4029785499217\n",
      "--------------------------------------------------\n",
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  109.64915198512354\n"
     ]
    }
   ],
   "source": [
    "from common import config\n",
    "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
    "# ==============================================\n",
    "config.GPU = False\n",
    "# ==============================================\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity, to_gpu\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "if config.GPU:\n",
    "    corpus = to_gpu(corpus)\n",
    "    corpus_val = to_gpu(corpus_val)\n",
    "    corpus_test = to_gpu(corpus_test)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
    "                time_size=time_size, max_grad=max_grad)\n",
    "\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티: ', ppl)\n",
    "\n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "\n",
    "    model.reset_state()\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 그냥 LSTM과 개선된 LSTM을 비교하기 위하여 Epoch를 4로 설정하고 Train하는 중 이다.  \n",
    "실제 Epoch를 40으로하여 Trainning된 Model은 아래 링크에서 제공되고 있다.\n",
    "\n",
    "<a href=\"http://www.oreilly.co.jp/pub/9784873118369/BetterRnnlm.pkl\">BetterRnnlm.pkl 다운로드</a><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
